---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Recovering Individual Mental Representations of Facial Affect Using Variational
  Auto-Encoder Guided Markov Chain Monte Carlo with People
subtitle: ''
summary: ''
authors:
- Haijiang Yan
- Nick Chater
- Christian Tsvetkov
- Adam Sanborn
tags: []
categories: []
date: '2024-01-01'
lastmod: 2024-09-12T18:12:07+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2024-09-12T17:12:07.366458Z'
publication_types:
- '2'
abstract: People's mental representations of complex stimuli, such as images of facial
  affect, are difficult to elicit. To address this challenge, methods such as Markov
  Chain Monte Carlo with People (MCMCP), integrate human agents into computer-based
  sampling algorithms. However, such methods suffer from slow convergence, making
  them impractical for recovering the representations of individuals. Here, we extended
  MCMCP by introducing an adapted Variational Auto-Encoder (VAE) with domain knowledge
  as an auxiliary agent, guiding the sampling process away from less useful experimental
  trials. To test this approach, we ran a new experiment comparing such a VAE-guided
  MCMCP against baseline MCMCP in terms of convergence speed and quality of recovering
  human representations of facial affect. Preliminary results demonstrated that most
  guided chains converged on an individual's facial affect representation within a
  single experimental session, faster than the baseline methods, and results showed
  the extent of individual differences in facial affect representations. Thus, VAE-guided
  MCMCP provides a promising framework for interfacing machine intelligence with psychological
  experiments to enhance our understanding of human cognition.
publication: '*Proceedings of the Annual Meeting of the Cognitive Science Society*'
---
