---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Introducing the MindSet Benchmark for Comparing DNNs to Human Vision
subtitle: ''
summary: ''
authors:
- Valerio Biscione
- Dong Yin
- Gaurav Malhotra
- Marin DujmoviÄ‡
- Milton Montero
- Guillermo Puebla
- Federico G. Adolfi
- Christian Tsvetkov
- Rachel Flood Heaton
- John Hummel
- Brad Evans
- Jeffrey S. Bowers
tags: []
categories: []
date: '2023-04-01'
lastmod: 2024-09-12T18:12:06+01:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2024-09-12T17:12:06.541424Z'
publication_types:
- '0'
abstract: We describe the MindSet benchmark designed to facilitate the testing of
  DNNs against controlled experiments reported in psychology.  MindSet will focus
  on a range of low-, middle-, and high-level visual findings that provide important
  constraints for theory, provide the materials for testing DNNs, and provide an example
  of how to assess a DNN on each experiment using a ResNet152 pretrained on ImageNet.
  The goal is not to evaluate how well ResNet152 accounts for human vision, but rather,
  encourage researchers to assess how well various DNNs account for a range of key
  human visual phenomena.
publication: '*OSF*'
doi: 10.31234/osf.io/cneyp
---
